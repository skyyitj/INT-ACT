#!/usr/bin/env python3
"""
å¿«é€Ÿæ¼”ç¤ºAffordanceåŠŸèƒ½

è¿è¡Œè¿™ä¸ªè„šæœ¬å¯ä»¥å¿«é€Ÿçœ‹åˆ°affordanceçš„æ•ˆæœ
"""

import numpy as np
import cv2
import simpler_env
from get_pose_corrected_coordinates import add_affordance_to_observation, get_robot_pose_and_image_from_env
from simpler_env.utils.env.observation_utils import get_image_from_maniskill2_obs_dict


def quick_demo():
    """å¿«é€Ÿæ¼”ç¤ºï¼šç”Ÿæˆå¯¹æ¯”å›¾"""
    print("=" * 60)
    print("Affordanceå¿«é€Ÿæ¼”ç¤º")
    print("=" * 60)
    print("\næ­£åœ¨åˆå§‹åŒ–ç¯å¢ƒ...")

    task_name = "widowx_carrot_on_plate"
    env = simpler_env.make(task_name)

    try:
        obs, reset_info = env.reset(seed=42)
        print("âœ“ ç¯å¢ƒå·²åˆå§‹åŒ–\n")

        # è·å–åŸå§‹å›¾åƒ
        print("æ­£åœ¨è·å–åŸå§‹å›¾åƒ...")
        if "image" in obs:
            cam_imgs = obs["image"]
            if "3rd_view_camera" in cam_imgs and "rgb" in cam_imgs["3rd_view_camera"]:
                img_original = cam_imgs["3rd_view_camera"]["rgb"].copy()
            elif "base_camera" in cam_imgs and "rgb" in cam_imgs["base_camera"]:
                img_original = cam_imgs["base_camera"]["rgb"].copy()
            else:
                img_original = get_image_from_maniskill2_obs_dict(env, obs)
        else:
            img_original = get_image_from_maniskill2_obs_dict(env, obs)

        print(f"âœ“ åŸå§‹å›¾åƒå¤§å°: {img_original.shape}\n")

        # æ·»åŠ affordance
        print("æ­£åœ¨æ·»åŠ affordance...")
        obs_with_aff = add_affordance_to_observation(
            obs, env,
            arrow_color=(0, 255, 0),  # ç»¿è‰²
            arrow_thickness=4,
            arrow_length=0.08,
            show_point=True
        )
        print("âœ“ Affordanceå·²æ·»åŠ \n")

        # è·å–å¸¦affordanceçš„å›¾åƒ
        if "image" in obs_with_aff:
            cam_imgs = obs_with_aff["image"]
            if "3rd_view_camera" in cam_imgs and "rgb" in cam_imgs["3rd_view_camera"]:
                img_affordance = cam_imgs["3rd_view_camera"]["rgb"]
            elif "base_camera" in cam_imgs and "rgb" in cam_imgs["base_camera"]:
                img_affordance = cam_imgs["base_camera"]["rgb"]
            else:
                img_affordance = get_image_from_maniskill2_obs_dict(env, obs_with_aff)
        else:
            img_affordance = get_image_from_maniskill2_obs_dict(env, obs_with_aff)

        # ä¿å­˜å›¾åƒ
        print("æ­£åœ¨ä¿å­˜å›¾åƒ...")
        cv2.imwrite('demo_original.png', cv2.cvtColor(img_original, cv2.COLOR_RGB2BGR))
        cv2.imwrite('demo_with_affordance.png', cv2.cvtColor(img_affordance, cv2.COLOR_RGB2BGR))
        print("âœ“ ä¿å­˜: demo_original.png")
        print("âœ“ ä¿å­˜: demo_with_affordance.png")

        # åˆ›å»ºå¯¹æ¯”å›¾
        print("\næ­£åœ¨åˆ›å»ºå¯¹æ¯”å›¾...")

        # æ·»åŠ æ ‡ç­¾
        img_orig_labeled = img_original.copy()
        img_aff_labeled = img_affordance.copy()

        cv2.putText(img_orig_labeled, "Original", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(img_aff_labeled, "With Affordance", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        # æ°´å¹³æ‹¼æ¥
        comparison = np.hstack([img_orig_labeled, img_aff_labeled])
        cv2.imwrite('demo_comparison.png', cv2.cvtColor(comparison, cv2.COLOR_RGB2BGR))
        print("âœ“ ä¿å­˜: demo_comparison.png")

        # æ‰“å°ä½å§¿ä¿¡æ¯
        print("\n" + "=" * 60)
        print("å¤¹çˆªä½å§¿ä¿¡æ¯:")
        print("=" * 60)
        data = get_robot_pose_and_image_from_env(env, obs)
        print(f"3Dä½ç½®: {data['position']}")
        print(f"å››å…ƒæ•°: {data['quaternion']}")
        print(f"å¤¹çˆªå¼€åˆåº¦: {data['gripper_width']:.3f}")

        print("\n" + "=" * 60)
        print("æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 60)
        print("\nç”Ÿæˆçš„æ–‡ä»¶:")
        print("  1. demo_original.png - åŸå§‹è§‚æµ‹å›¾åƒ")
        print("  2. demo_with_affordance.png - æ·»åŠ affordanceçš„å›¾åƒ")
        print("  3. demo_comparison.png - å¯¹æ¯”å›¾")

        print("\nğŸ’¡ æç¤º:")
        print("  - ç»¿è‰²ç®­å¤´è¡¨ç¤ºå¤¹çˆªçš„æœå‘ï¼ˆXè½´æ–¹å‘ï¼‰")
        print("  - ç®­å¤´èµ·ç‚¹çš„åœ†ç‚¹è¡¨ç¤ºå¤¹çˆªçš„ä½ç½®")
        print("  - è¿™ä¸ªaffordanceå¯ä»¥å¸®åŠ©ç­–ç•¥æ›´å¥½åœ°ç†è§£æ“ä½œæ–¹å‘")

        print("\nä¸‹ä¸€æ­¥:")
        print("  1. æŸ¥çœ‹ç”Ÿæˆçš„å›¾åƒ")
        print("  2. è¿è¡Œ 'python get_pose_corrected_coordinates.py --affordance' æŸ¥çœ‹æ›´å¤šæ ·å¼")
        print("  3. è¿è¡Œ 'python affordance_usage_guide.py' å­¦ä¹ å¦‚ä½•é›†æˆåˆ°ä½ çš„ä»£ç ")
        print("  4. è¿è¡Œ 'python affordance_wrapper.py' æµ‹è¯•ç¯å¢ƒåŒ…è£…å™¨")

        return True

    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        env.close()


if __name__ == "__main__":
    success = quick_demo()
    exit(0 if success else 1)

